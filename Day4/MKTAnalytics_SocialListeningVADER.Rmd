---
title: ""
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r install packages}
# only need to run once if you don't have it
#install.packages("readxl")
#install.packages("sqldf")
#install.packages("vader")
# install if you don't have it. 
# only need to run this once, ever
```

```{r}
# don't show warnings while knitting
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r libraries}
library(readxl); library(sqldf); library(vader)
```

```{r}
vader::get_vader("The texture is terrible.  Fragrance is nice though.")
```

```{r constants}
# constants
my_working_dir_mac <- "~/Desktop/MKTAnalytics/Data/Sephora" # working directory if on a Mac
my_working_dir_pc <- "D:\\onurg\\Documents\\MKT 326\\Day5" # if on a PC

myFile_products <- "products.csv"
myFile_reviews <- "reviews.csv"
myFile_authors <- "authors.csv"
```

```{r import data from Excel, on a Mac OS computer}
# import data
setwd(my_working_dir_pc)
products <- read.csv(myFile_products)
reviews <- read.csv(myFile_reviews)
authors <- read.csv(myFile_authors)
```

```{r take a look at reviews table}
# take a look at the last 6 rows of a table
tail(reviews)
```

```{r Sentiment analysis}
# calculate VADER sentiments
# first, create a placeholder table, "d"
d <- sqldf("
  SELECT  review_id AS ReviewId, review_text AS ReviewText, 
          0 AS Pos, 0 AS Neu, 0 AS Neg, 0 AS But, 0 AS Compound
  FROM  reviews
")

# then, loop through each review and calculate VADER
for (i in 1:nrow(d)){ #will take ~2 to 10 min., literally
#for (i in 1:5){
  voutput <- get_vader(d[i,2])
  pos <- as.numeric(voutput["pos"])
  neu <- as.numeric(voutput["neu"])
  neg <- as.numeric(voutput["neg"])
  but <- as.numeric(voutput["but_count"])
  compound <- as.numeric(voutput["compound"])
  
  # store the VADER scores inside the placeholder table "d"
  d[i,3] <- pos
  d[i,4] <- neu
  d[i,5] <- neg
  d[i,6] <- but
  d[i,7] <- compound
}

```
  
```{r}
# a sql INNER JOIN to merge reviews with the VADER sentiments we calculated
reviews <- sqldf(
  "SELECT r.*, d.pos, d.neu, d.neg, d.but, d.compound
   FROM   reviews r INNER JOIN d ON
    r.review_id = d.ReviewId
  ")
```

```{r}
# output the top 10 lines from a table
head(reviews, 10)
```

```{r 1 star avgerage sentiments}
# average VADER sentiments for 1-star reviews
sqldf("
      SELECT AVG(Pos) AS AvgPos, AVG(Neu) AS AvgNeu, AVG(Neg) AS AvgNeg,
            AVG(But) AS AvgBut, AVG(Compound) AS AvgCompound
      FROM  reviews
      WHERE rating = 1
      ")
```

```{r 5 star average sentiments}
# average VADER sentiments for 5-star reviews
sqldf("
      SELECT AVG(Pos) AS AvgPos, AVG(Neu) AS AvgNeu, AVG(Neg) AS AvgNeg,
            AVG(But) AS AvgBut, AVG(Compound) AS AvgCompound
      FROM  reviews
      WHERE rating = 5
      ")
```

```{r are the sentiment scores statistically different, 5 star versus 1 star}
# t test. Are the sentiment scores statistically different, 5 star versus 1 star
t.test(reviews[reviews$rating == 5, ]$Compound, reviews[reviews$rating == 1, ]$Compound)
```

```{r average length of reviews}
# what is the average length of reviews
# first calculate the lengths in characters
reviews$ReviewTextChars <- nchar(reviews$review_text)

# then take the mean
mean(reviews$ReviewTextChars)
```

```{r select top 30 rows by review length}
# select the top 30 rows by review length in SQL
# in other words, here is the list of reviews with the 30 longest lengths
sqldf(" SELECT * 
        FROM reviews
        ORDER BY ReviewTextChars DESC
        LIMIT 30
      ")
```

```{r select bottom 30 rows by review length}
# select the bottom 30 rows by review length in SQL
# in other words, here is the list of reviews with the shortest lengths
sqldf(" SELECT * 
        FROM reviews
        ORDER BY ReviewTextChars ASC
        LIMIT 30
      ")
```

```{r write out the data}
setwd(my_working_dir_mac)
write.csv(reviews, "reviews_updated.csv")
```


